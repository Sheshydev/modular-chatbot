{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.db_client import DB_Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "import nlpaug.augmenter.word as naw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = DB_Client()\n",
    "model = joblib.load(\"models/movie_trivia.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv('eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred = model.predict(\"What is Bubba's name in Forest Gump?\") # we get a sample prediction output to obtain the output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the intent ids from the sample prediction for use in one-hot-encoding\n",
    "intent_ids = [prediction[0] for prediction in sample_pred]\n",
    "intent_ids.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg(row):\n",
    "    question = row['question']\n",
    "    intent_id = row[1]\n",
    "    encoded_intent = list(map(lambda x: 1 if x == intent_id else 0, intent_ids))\n",
    "    encoded_intent = np.asarray([encoded_intent])\n",
    "    model_pred = model.predict(question)\n",
    "    model_pred.sort(key=lambda x: x[0])\n",
    "    model_pred = [prediction[1] for prediction in model_pred]\n",
    "    model_pred = np.asarray([model_pred])\n",
    "    return ndcg_score(encoded_intent, model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['ndcg'] = eval_data.apply(get_ndcg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ndcg = eval_data['ndcg'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630929753571458"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typofy(text, percentage):\n",
    "    percent = percentage\n",
    "    nocharrepl = len(text) * percent\n",
    "    for _ in range(int(nocharrepl)):\n",
    "        repl_idx = random.randint(0, len(text)-1)\n",
    "        if repl_idx == 0:\n",
    "            text = random.choice('abcdefghijklmnopqrstuvwxyz') + text[repl_idx + 1:]\n",
    "        elif repl_idx == len(text)-1:\n",
    "            text = text[:repl_idx] + random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "        else:\n",
    "            text = text[:repl_idx] + random.choice('abcdefghijklmnopqrstuvwxyz') + text[repl_idx + 1:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_typo(row):\n",
    "    question = row['question']\n",
    "    return typofy(question, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4213688435435202"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_means = []\n",
    "for _ in range(100):\n",
    "    # to repeat the experiment of a single typo percentage 100 times\n",
    "    eval_data_typo = eval_data.apply(simulate_typo, axis=1)\n",
    "    typo = pd.DataFrame(eval_data_typo, columns=['question'])\n",
    "    typo['intentID'] = eval_data[' intentID']\n",
    "    typo['ndcg'] = typo.apply(get_ndcg, axis=1)\n",
    "    ndcg_means.append(typo['ndcg'].mean())\n",
    "\n",
    "avg_ndcg_typo = sum(ndcg_means) / len(ndcg_means)\n",
    "avg_ndcg_typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data.drop(columns=['question_typo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data.to_csv('./eval_data/eval_0_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('haichatbot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3dea1c492db40c4abfe16025dd233c037b49644f42709b8560ce54759048ede"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
